{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350c4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ffe9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db82ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data shape:  (2919, 79)\n",
      "\n",
      "================================================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Features with missing values: 34\n",
      "\n",
      "Top 20 features with missing values:\n",
      "              Missing_Count  Percentage\n",
      "PoolQC                 2909       99.66\n",
      "MiscFeature            2814       96.40\n",
      "Alley                  2721       93.22\n",
      "Fence                  2348       80.44\n",
      "MasVnrType             1766       60.50\n",
      "FireplaceQu            1420       48.65\n",
      "LotFrontage             486       16.65\n",
      "GarageQual              159        5.45\n",
      "GarageYrBlt             159        5.45\n",
      "GarageCond              159        5.45\n",
      "GarageFinish            159        5.45\n",
      "GarageType              157        5.38\n",
      "BsmtExposure             82        2.81\n",
      "BsmtCond                 82        2.81\n",
      "BsmtQual                 81        2.77\n",
      "BsmtFinType2             80        2.74\n",
      "BsmtFinType1             79        2.71\n",
      "MasVnrArea               23        0.79\n",
      "MSZoning                  4        0.14\n",
      "BsmtFullBath              2        0.07\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/raw/train.csv')\n",
    "test_df = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "y_train = train_df['SalePrice'].copy()\n",
    "test_ids = test_df['Id'].copy()\n",
    "\n",
    "train_df.drop(['Id','SalePrice'], axis=1, inplace=True)\n",
    "test_df.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "n_train = train_df.shape[0]\n",
    "all_data = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(\"All data shape: \", all_data.shape)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing = all_data.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "missing_percent = (missing / len(all_data) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "\n",
    "print(f\"\\nFeatures with missing values: {len(missing_df)}\")\n",
    "print(\"\\nTop 20 features with missing values:\")\n",
    "print(missing_df.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e4df92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Total remaining missing values after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling missing values...\")\n",
    "\n",
    "none_features = [\n",
    "    'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
    "    'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "    'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "    'MasVnrType'\n",
    "]\n",
    "\n",
    "for feature in none_features:\n",
    "    if feature in all_data.columns:\n",
    "        all_data[feature] = all_data[feature].fillna('None')\n",
    "\n",
    "zero_features = [   \n",
    "    'GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "    'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    "    'BsmtFullBath', 'BsmtHalfBath',\n",
    "    'MasVnrArea'\n",
    "]\n",
    "\n",
    "for feature in zero_features:\n",
    "    if feature in all_data.columns:\n",
    "        all_data[feature] = all_data[feature].fillna(0)\n",
    "\n",
    "\n",
    "if 'LotFrontage' in all_data.columns:\n",
    "    all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "if 'MSZoning' in all_data.columns:\n",
    "    all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
    "\n",
    "\n",
    "if 'Utilities' in all_data.columns:\n",
    "    all_data['Utilities'] = all_data['Utilities'].fillna(all_data['Utilities'].mode()[0])\n",
    "\n",
    "\n",
    "if 'Functional' in all_data.columns:\n",
    "    all_data['Functional'] = all_data['Functional'].fillna(all_data['Functional'].mode()[0])\n",
    "\n",
    "if 'Exterior1st' in all_data.columns:\n",
    "    all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "\n",
    "if 'Exterior2nd' in all_data.columns:\n",
    "    all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "\n",
    "\n",
    "if 'KitchenQual' in all_data.columns:\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "\n",
    "\n",
    "if 'Electrical' in all_data.columns:\n",
    "    all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "\n",
    "\n",
    "if 'SaleType' in all_data.columns:\n",
    "    all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "\n",
    "remaining_missing = all_data.isnull().sum().sum()\n",
    "\n",
    "print(f\"Total remaining missing values after imputation: {remaining_missing}\")\n",
    "\n",
    "if remaining_missing > 0:\n",
    "    print(\"\\nFeatures still with missing values:\")\n",
    "    print(all_data.isnull().sum()[all_data.isnull().sum() > 0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7402cec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featuring Engineering\n",
      "New Data shape after feature engineering: (2919, 93)\n"
     ]
    }
   ],
   "source": [
    "print('Featuring Engineering')\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "all_data['TotalBath'] = (all_data['FullBath'] + \n",
    "                          all_data['HalfBath'] * 0.5 + \n",
    "                          all_data['BsmtFullBath'] + \n",
    "                          all_data['BsmtHalfBath'] * 0.5)\n",
    "\n",
    "all_data['TotalPorchSF'] = (all_data['OpenPorchSF'] +\n",
    "                            all_data['EnclosedPorch'] +\n",
    "                            all_data['3SsnPorch'] +\n",
    "                            all_data['ScreenPorch']+\n",
    "                            all_data['WoodDeckSF']\n",
    "                            )\n",
    "\n",
    "all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "all_data['RemodAge'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "all_data['IsRemod'] = (all_data['YearBuilt'] != all_data['YearRemodAdd']).astype(int)\n",
    "\n",
    "all_data['Has2ndFloor'] = (all_data['2ndFlrSF'] > 0).astype(int)\n",
    "all_data['HasGarage'] = (all_data['GarageArea'] > 0).astype(int)\n",
    "all_data['HasBasement'] = (all_data['TotalBsmtSF'] > 0).astype(int)\n",
    "all_data['HasPorch'] = (all_data['TotalPorchSF'] > 0).astype(int)\n",
    "all_data['HasPool'] = (all_data['PoolArea'] > 0).astype(int)\n",
    "all_data['HasFireplace'] = (all_data['Fireplaces'] > 0).astype(int)\n",
    "all_data['OverallQualCond'] = all_data['OverallQual'] * all_data['OverallCond']\n",
    "all_data['LivAreaPerRoom'] = all_data['GrLivArea'] / (all_data['TotRmsAbvGrd'] + 1)\n",
    "\n",
    "print(f\"New Data shape after feature engineering: {all_data.shape}\")\n",
    "\n",
    "\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71c5cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droppig unnecessary features\n",
      "Dropped 11 features\n",
      "Features dropped: ['Utilities', 'Street', 'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'MoSold']\n",
      "New data shape: (2919, 82)\n"
     ]
    }
   ],
   "source": [
    "print('Droppig unnecessary features')\n",
    "\n",
    "drop_features = [\n",
    "    'Utilities', 'Street', 'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt',\n",
    "      'MoSold'\n",
    "]\n",
    "\n",
    "drop_features = [f for f in drop_features if f in all_data.columns]\n",
    "all_data = all_data.drop(drop_features, axis=1)\n",
    "\n",
    "print(f\"Dropped {len(drop_features)} features\")\n",
    "print(f\"Features dropped: {drop_features}\")\n",
    "print(f\"New data shape: {all_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1a1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handlig skewed features\n"
     ]
    }
   ],
   "source": [
    "print('Handling skewed features')\n",
    "\n",
    "# First check for infinite values\n",
    "numeric_feats = all_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "inf_check = np.isinf(all_data[numeric_feats]).sum().sum()\n",
    "if inf_check > 0:\n",
    "    print(f\"Found {inf_check} infinite values before transformation\")\n",
    "    all_data = all_data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = all_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "high_skew = skewness[abs(skewness) > 0.5]\n",
    "\n",
    "print(f\"\\nFeatures with high skewness (>0.5): {len(high_skew)}\")\n",
    "print(\"\\nTop 10 most skewed features:\")\n",
    "print(high_skew.head(10))\n",
    "\n",
    "# Apply log transformation with safety checks\n",
    "for feat in high_skew.index:\n",
    "    if feat in all_data.columns:\n",
    "        # Add a small constant to avoid log(0)\n",
    "        min_val = all_data[feat].min()\n",
    "        if min_val <= 0:\n",
    "            offset = abs(min_val) + 1\n",
    "            all_data[feat] = np.log1p(all_data[feat] + offset)\n",
    "        else:\n",
    "            all_data[feat] = np.log1p(all_data[feat])\n",
    "\n",
    "# Check for any remaining infinite values\n",
    "inf_check = np.isinf(all_data[numeric_feats]).sum().sum()\n",
    "if inf_check > 0:\n",
    "    print(f\"\\nWarning: Found {inf_check} infinite values after transformation\")\n",
    "    # Replace any remaining infinities with NaN\n",
    "    all_data = all_data.replace([np.inf, -np.inf], np.nan)\n",
    "    # Fill NaN with median of the column\n",
    "    all_data = all_data.fillna(all_data.median())\n",
    "\n",
    "# Transform target variable\n",
    "y_train_log = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd4c8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical features\n",
      "Ordinal encoded 17 features\n"
     ]
    }
   ],
   "source": [
    "print('Encoding categorical features')\n",
    "\n",
    "categorical_feats = all_data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "ordinal_mappings = {\n",
    "    'ExterQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'ExterCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'BsmtQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'BsmtCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'HeatingQC': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'GarageQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'GarageCond': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5, 'None': 0},\n",
    "    'BsmtExposure': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "    'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "    'Functional': {'Sal': 1, 'Sev': 2, 'Maj2': 3, 'Maj1': 4, 'Mod': 5, 'Min2': 6, 'Min1': 7, 'Typ': 8},\n",
    "    'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},\n",
    "    'PavedDrive': {'N': 0, 'P': 1, 'Y': 2},\n",
    "    'LotShape': {'IR3': 1, 'IR2': 2, 'IR1': 3, 'Reg': 4},\n",
    "    'LandContour': {'Low': 1, 'HLS': 2, 'Bnk': 3, 'Lvl': 4},\n",
    "    'LandSlope': {'Sev': 1, 'Mod': 2, 'Gtl': 3}\n",
    "}\n",
    "\n",
    "for feat, mapping in ordinal_mappings.items():\n",
    "    if feat in all_data.columns:\n",
    "        all_data[feat] = all_data[feat].map(mapping)\n",
    "\n",
    "print(f\"Ordinal encoded {len(ordinal_mappings)} features\")\n",
    "\n",
    "remaining_categorical = all_data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if len(remaining_categorical) > 0:\n",
    "    print(f\"\\nOne-hot encoding {len(remaining_categorical)} remaining categorical features...\")\n",
    "    all_data = pd.get_dummies(all_data, columns=remaining_categorical, drop_first=True)\n",
    "    print(f\"One-hot encoding complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "132b5841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test split\n",
      "X_train shape: (1460, 199)\n",
      "X_test shape: (1459, 199)\n",
      "y_train shape: (1460,)\n"
     ]
    }
   ],
   "source": [
    "print('Train test split')\n",
    "\n",
    "X_train = all_data.iloc[:n_train, :].copy()\n",
    "X_test = all_data.iloc[n_train:, :].copy()\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train_log.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aa1843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling outliers\n",
      "No significant outliers detected\n"
     ]
    }
   ],
   "source": [
    "print('Handling outliers')\n",
    "\n",
    "outlier_indices = X_train[(X_train['GrLivArea'] > 4000) & (y_train < 300000)].index\n",
    "\n",
    "if len(outlier_indices) > 0:\n",
    "    print(f\"Removing {len(outlier_indices)} outliers from training data\")\n",
    "    X_train = X_train.drop(outlier_indices)\n",
    "    y_train_log = y_train_log.drop(outlier_indices)\n",
    "    print(f\"Outliers removed\")\n",
    "else:\n",
    "    print(\"No significant outliers detected\")\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c112f1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling\n",
      "\n",
      "Checking Training data:\n",
      "Found 24820 NaN values\n",
      "\n",
      "Checking Test data:\n",
      "Found 1 infinite values\n",
      "Found 24803 NaN values\n",
      "\n",
      "After scaling:\n",
      "\n",
      "Checking Scaled training data:\n",
      "Found 24820 NaN values\n",
      "\n",
      "Checking Scaled test data:\n",
      "Found 24803 NaN values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Feature scaling')\n",
    "\n",
    "# First check for any problematic values\n",
    "def check_data_issues(data, name):\n",
    "    inf_count = np.isinf(data.select_dtypes(include=[np.number])).sum().sum()\n",
    "    nan_count = data.isnull().sum().sum()\n",
    "    print(f\"\\nChecking {name}:\")\n",
    "    if inf_count > 0:\n",
    "        print(f\"Found {inf_count} infinite values\")\n",
    "    if nan_count > 0:\n",
    "        print(f\"Found {nan_count} NaN values\")\n",
    "    return inf_count == 0 and nan_count == 0\n",
    "\n",
    "# Check and clean training data\n",
    "check_data_issues(X_train, \"Training data\")\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_train = X_train.fillna(X_train.median())\n",
    "\n",
    "# Check and clean test data\n",
    "check_data_issues(X_test, \"Test data\")\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.fillna(X_test.median())\n",
    "\n",
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Verify no issues after scaling\n",
    "print(\"\\nAfter scaling:\")\n",
    "check_data_issues(X_train_scaled, \"Scaled training data\")\n",
    "check_data_issues(X_test_scaled, \"Scaled test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffa4e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "X_train_scaled.to_csv('../data/processed/X_train_processed.csv', index=False)\n",
    "X_test_scaled.to_csv('../data/processed/X_test_processed.csv', index=False)\n",
    "y_train_log.to_csv('../data/processed/y_train_log.csv', index=False, header=['SalePrice_log'])\n",
    "test_ids.to_csv('../data/processed/test_ids.csv', index=False, header=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc3e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
